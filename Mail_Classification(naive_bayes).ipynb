{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx6eVlHTdusOGNxMU7X4Qg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ds-upin/Email-Classifier/blob/main/Mail_Classification(naive_bayes).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data need to be diverse across various domains 50k mails might be enough"
      ],
      "metadata": {
        "id": "0-ED7_ex5yDN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gMw9dMw8OJH8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "df = kagglehub.dataset_load(\n",
        "   KaggleDatasetAdapter.PANDAS,\n",
        "   \"venky73/spam-mails-dataset\",\n",
        "   \"spam_ham_dataset.csv\"\n",
        ")\n",
        "df2 = kagglehub.dataset_load(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"meruvulikith/190k-spam-ham-email-dataset-for-classification\",\n",
        "  \"spam_Emails_data.csv\"\n",
        ")\n",
        "df = df[['label', 'text']]\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "df2 = df2[['label', 'text']]\n",
        "df2['label'] = df2['label'].map({'Ham': 0, 'Spam': 1})\n",
        "df = pd.concat([df, df2], ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mBRtJ_LOZkD",
        "outputId": "74e86128-7d31-498b-fdd3-5d35034a9243"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'spam-mails-dataset' dataset.\n",
            "Using Colab cache for faster access to the '190k-spam-ham-email-dataset-for-classification' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+', ' <URL> ', text)\n",
        "    text = re.sub(r'\\d+', ' <NUM> ', text)\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "bBZj3SkBPmiR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        max_features=5000,\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=3,\n",
        "        max_df=0.9,\n",
        "        stop_words='english'\n",
        "    )),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBFKwpZeOZzN",
        "outputId": "2be3b07b-238e-44e1-d760-9a40a7d0a809"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9400326592136666\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94     21167\n",
            "           1       0.95      0.92      0.94     18638\n",
            "\n",
            "    accuracy                           0.94     39805\n",
            "   macro avg       0.94      0.94      0.94     39805\n",
            "weighted avg       0.94      0.94      0.94     39805\n",
            "\n",
            "Confusion Matrix:\n",
            " [[20244   923]\n",
            " [ 1464 17174]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spam_random_mail = [ \"\"\"\n",
        "Earn a gift card by providing feedback on our React and Next.js SDKs which we're looking to enhance next year.\n",
        "We also highlight our n8n integration, a couple of new MediaFlows use cases, and our new HDR video support.\n",
        "Happy Holidays and we look forward to connecting in 2026!\n",
        "\"\"\",\n",
        "\n",
        "\"\"\"Dear Customer,\n",
        "\n",
        "Congratulations! ðŸŽ‰\n",
        "You have been selected as the winner of a $5,000 cash reward in our international promotion.\n",
        "\n",
        "To receive your prize, you must verify your account immediately.\n",
        "Failure to act within 24 hours will result in cancellation of your reward.\n",
        "\n",
        "ðŸ‘‰ Click here to claim your prize now:\n",
        "http://secure-verification-reward.com/claim\n",
        "\n",
        "This is a limited-time offer. Act now to avoid losing your money.\n",
        "\n",
        "Best regards,\n",
        "Customer Rewards Team\"\"\"]\n",
        "predictions = pipeline.predict(spam_random_mail)\n",
        "print(['Spam' if i==1 else 'Ham' for i in predictions])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv9QrosjRiBU",
        "outputId": "040d240e-a453-416d-9e94-635a81f69e19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Spam', 'Spam']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(pipeline, 'spam_classifier.joblib')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMQXHcR-Whzw",
        "outputId": "fa1def67-9df5-43cc-eab8-490348b97318"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spam_classifier.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}